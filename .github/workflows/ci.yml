name: CI

on:
  push:
    branches:
      - master
  pull_request:
    branches:
      - master

jobs:
  build-test:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        toolchain: [gcc, clang]
        sanitizer: [none, asan, ubsan, tsan]
        exclude:
          # Prefer clang for TSan (better support, fewer false positives).
          - toolchain: gcc
            sanitizer: tsan
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y cmake ninja-build pkg-config libgtest-dev
          if [ "${{ matrix.toolchain }}" = "clang" ]; then
            sudo apt-get install -y clang
          else
            sudo apt-get install -y g++
          fi

          # Ubuntu's libgtest-dev may ship sources; build and install the libs so find_package(GTest) works.
          if [ -d /usr/src/gtest ]; then
            cd /usr/src/gtest
            sudo cmake -S . -B build
            sudo cmake --build build -j
            sudo cmake --install build
          elif [ -d /usr/src/googletest ]; then
            cd /usr/src/googletest
            sudo cmake -S . -B build
            sudo cmake --build build -j
            sudo cmake --install build
          fi

      - name: Build and run tests
        env:
          CC: ${{ matrix.toolchain == 'clang' && 'clang' || 'gcc' }}
          CXX: ${{ matrix.toolchain == 'clang' && 'clang++' || 'g++' }}
        run: |
          chmod +x ./build.sh
          if [ "${{ matrix.sanitizer }}" = "asan" ]; then
            ./build.sh -c -t --asan
          elif [ "${{ matrix.sanitizer }}" = "ubsan" ]; then
            ./build.sh -c -t --ubsan
          elif [ "${{ matrix.sanitizer }}" = "tsan" ]; then
            ./build.sh -c -t --tsan
          else
            ./build.sh -c -t
          fi

  install-test:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y cmake ninja-build pkg-config g++

      - name: Build and install
        run: |
          chmod +x ./build.sh
          ./build.sh -c -r
          cmake --install build --prefix "$PWD/_install"

      - name: Build consumer with find_package
        run: |
          mkdir -p /tmp/iocoro-consumer
          cat > /tmp/iocoro-consumer/CMakeLists.txt <<'EOF'
          cmake_minimum_required(VERSION 3.15)
          project(iocoro_consumer LANGUAGES CXX)

          set(CMAKE_CXX_STANDARD 20)
          set(CMAKE_CXX_STANDARD_REQUIRED ON)
          set(CMAKE_CXX_EXTENSIONS OFF)

          find_package(iocoro REQUIRED)

          add_executable(consumer main.cpp)
          target_link_libraries(consumer PRIVATE iocoro::iocoro)
          EOF

          cat > /tmp/iocoro-consumer/main.cpp <<'EOF'
          #include <iocoro/iocoro.hpp>
          #include <chrono>

          using namespace std::chrono_literals;

          auto task() -> iocoro::awaitable<void> {
            co_await iocoro::co_sleep(1ms);
          }

          int main() {
            iocoro::io_context ctx;
            iocoro::co_spawn(ctx.get_executor(), task(), iocoro::detached);
            ctx.run();
            return 0;
          }
          EOF

          cmake -S /tmp/iocoro-consumer -B /tmp/iocoro-consumer/build -G Ninja \
            -DCMAKE_PREFIX_PATH="$PWD/_install"
          cmake --build /tmp/iocoro-consumer/build -j
          /tmp/iocoro-consumer/build/consumer

  perf-regression-gate:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y cmake ninja-build pkg-config g++ libboost-dev python3-jsonschema

      - name: Build benchmarks
        run: |
          cmake -S . -B build -G Ninja -DCMAKE_BUILD_TYPE=Release -DIOCORO_BUILD_BENCHMARKS=ON
          cmake --build build -j

      - name: Run perf baseline gate
        run: |
          ./benchmark/run_tcp_roundtrip_baseline.sh \
            --build-dir build \
            --iterations 3 \
            --warmup 1 \
            --run-timeout-sec 120 \
            --baseline benchmark/baseline/tcp_roundtrip_thresholds.txt \
            --report benchmark/perf_report.json | tee benchmark/perf_summary.txt

      - name: Validate roundtrip report schema
        run: |
          python3 benchmark/validate_perf_report.py \
            --schema benchmark/perf_report.schema.json \
            --report benchmark/perf_report.json

      - name: Run connect-accept baseline gate
        run: |
          ./benchmark/run_tcp_connect_accept_baseline.sh \
            --build-dir build \
            --iterations 3 \
            --warmup 1 \
            --run-timeout-sec 180 \
            --baseline benchmark/baseline/tcp_connect_accept_thresholds.txt \
            --report benchmark/connect_accept_report.json | tee benchmark/connect_accept_summary.txt

      - name: Validate connect-accept report schema
        run: |
          python3 benchmark/validate_perf_report.py \
            --schema benchmark/connect_accept_report.schema.json \
            --report benchmark/connect_accept_report.json

      - name: Upload perf artifacts
        uses: actions/upload-artifact@v4
        with:
          name: perf-regression-report
          path: |
            benchmark/perf_report.json
            benchmark/perf_summary.txt
            benchmark/connect_accept_report.json
            benchmark/connect_accept_summary.txt
